# -*- coding: utf-8 -*-
"""naive.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Se4laUqdJVrPUtcLphFwnezDmw8_F0Gu
"""

def JointProp(train_dataset,featurecolumn,labelcolumn="Car Acceptability"):
  
  keys_feature = np.array(train_dataset[featurecolumn].unique())


  keys_labels = np.array(train_dataset[labelcolumn].unique())


  p_feature_given_label = np.zeros((len(keys_feature), len(keys_labels)))


  for i in zip(train_dataset[featurecolumn], train_dataset[labelcolumn]):
  
      index_feature = np.where(keys_feature == i[0])
      
      
      index_label = np.where(keys_labels == i[1])
      
   
      p_feature_given_label[[index_feature], [index_label]] += 1


  df_p_feature_given_label = pd.DataFrame(p_feature_given_label, keys_feature, keys_labels)

  p_feature_given_label = p_feature_given_label / np.sum(p_feature_given_label, axis=0, keepdims=True)


  df_p_feature_given_label = pd.DataFrame(p_feature_given_label, keys_feature, keys_labels)

  
  return df_p_feature_given_label

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
df = pd.read_csv("car_data.csv",encoding_errors='ignore')

train_dataset,test_dataset=train_test_split(df, test_size=0.25, random_state=42)

# calculate probability of each class
keys_labels = np.array(train_dataset["Car Acceptability"].unique()) 
keys_count=np.zeros((len(keys_labels))) 
for currentLabel in train_dataset["Car Acceptability"]:
     
    index_label = np.where(keys_labels == currentLabel) 
    
    keys_count[index_label] += 1

p_labels = keys_count / np.sum(keys_count, axis=0, keepdims=True)
df_p_labels = pd.DataFrame(keys_count, keys_labels)

joint_buying=JointProp(train_dataset,featurecolumn="Buying Price",labelcolumn="Car Acceptability")
joint_doors=JointProp(train_dataset,featurecolumn="Number of Doors",labelcolumn="Car Acceptability")
joint_capacity=JointProp(train_dataset,featurecolumn="Capacity",labelcolumn="Car Acceptability")
joint_Boot=JointProp(train_dataset,featurecolumn="Size of Luggage Boot",labelcolumn="Car Acceptability")
joint_Safety=JointProp(train_dataset,featurecolumn="Car Safety",labelcolumn="Car Acceptability")
joint_Maintenance=JointProp(train_dataset,featurecolumn="Maintenance Price",labelcolumn="Car Acceptability")



correct = 0
for idx, item in test_dataset.iterrows():
    alpha = 1
    denominator = 0
    possibilities = {}
    for cls in keys_labels:
      
        p = 1
        p *= (joint_buying[cls][item["Buying Price"]])
        p *= (joint_Maintenance[cls][item["Maintenance Price"]])
        p *= (joint_doors[cls][item["Number of Doors"]])
        p *= (joint_capacity[cls][item["Capacity"]])
        p *= (joint_Boot[cls][item["Size of Luggage Boot"]])
        p *= (joint_Safety[cls][item["Car Safety"]])
        p *= df_p_labels[0][cls] 
        
        denominator += p 
        
        possibilities[cls] = p 
   
    
    possibilities.update({k: v / denominator for k, v in possibilities.items()})
    
   
    correct += max(possibilities, key=possibilities.get) == item["Car Acceptability"]


print("accuracy of Naive algorithm = %d%%" % ((correct / len(test_dataset)) * 100))

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
df = pd.read_csv("",encoding_errors='ignore')
print(df)